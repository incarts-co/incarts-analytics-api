Developer Guide: Building FastAPI Endpoints for Analytics DataObjective: Create a set of FastAPI endpoints to serve aggregated analytics data from the Supabase PostgreSQL data warehouse. This API will power dashboards similar to those prototyped with Metabase queries. The API should automatically generate OpenAPI (Swagger) documentation.1. Core Concepts & SetupData Source: The primary data source is a Supabase PostgreSQL database containing a dimensional model (star schema) with a central factlinkclicks table and various dimension tables (dimdate, dimlink, dimcampaign, etc.).API Goal: Expose aggregated data and KPIs based on the SQL queries defined in the "SQL Queries for Metabase Dashboards (Examples)" document (metabase_dashboard_queries).Technology Stack:FastAPI for building the API.Pydantic for data validation and serialization (request/response models).An async PostgreSQL driver like asyncpg is highly recommended for database interactions. SQLAlchemy (async version) can be used as an ORM or for query building if preferred, or raw SQL execution with asyncpg.Key API Features:Endpoints corresponding to major KPIs and charts.Query parameters for filtering (e.g., date ranges, campaign IDs, project IDs).Clear, Pydantic-defined response models.Automatic OpenAPI (Swagger UI at /docs and ReDoc at /redoc) documentation generated by FastAPI.Database Connection:Securely manage database connection strings (e.g., using environment variables).Implement a connection pool for efficient database access.Example (conceptual, using asyncpg):# main.py or database.py
import asyncpg
import os

DATABASE_URL = os.getenv("DATABASE_URL") # Your Supabase connection string
db_pool = None

async def get_db_pool():
    global db_pool
    if db_pool is None:
        db_pool = await asyncpg.create_pool(DATABASE_URL)
    return db_pool

# Dependency for FastAPI path operations
async def get_connection():
    pool = await get_db_pool()
    async with pool.acquire() as connection:
        yield connection
2. API Structure & EndpointsWe'll structure the API endpoints mirroring the dashboard organization. All endpoints should be versioned (e.g., /api/v1/...).2.1. Pydantic Models (Shared Schemas)Define common Pydantic models for consistent responses.# schemas.py
from typing import List, Optional, Dict
from pydantic import BaseModel
from datetime import date, datetime

class KPIResponse(BaseModel):
    value: float | int # Generic KPI value
    label: Optional[str] = None

class TrendDataItem(BaseModel):
    date: date | str # Could be date, month_year string, etc.
    value: int | float

class TrendResponse(BaseModel):
    data: List[TrendDataItem]

class BreakdownItem(BaseModel):
    category: str
    value: int | float

class BreakdownResponse(BaseModel):
    data: List[BreakdownItem]

class TableRow(BaseModel): # Generic table row, specific models might be better
    # Define fields based on table content
    # Example for Link Performance:
    link_name: Optional[str] = None
    short_link_url: Optional[str] = None
    link_type: Optional[str] = None
    total_clicks: Optional[int] = None
    atc_clicks: Optional[int] = None
    total_link_value: Optional[float] = None
    # Add other common fields as needed

class PaginatedTableResponse(BaseModel):
    total_items: int
    items: List[Dict] # Or List[SpecificTableRowModel]
    page: int
    size: int
    total_pages: int

# Add more specific response models as needed for complex chart data
2.2. Global Overview Dashboard Endpoints (/api/v1/overview/...)Reference SQL queries from section "I. QUERIES FOR 'GLOBAL OVERVIEW DASHBOARD'" in metabase_dashboard_queries.KPIs:Endpoint: GET /api/v1/overview/kpis/total_clicksQuery Params: start_date: date, end_date: dateResponse Model: KPIResponse(value: int)SQL Ref: "KPI: Total Clicks"Endpoint: GET /api/v1/overview/kpis/total_atc_clicksQuery Params: start_date: date, end_date: dateResponse Model: KPIResponse(value: int)SQL Ref: "KPI: Total 'Add to Cart' (ATC) Clicks"Endpoint: GET /api/v1/overview/kpis/total_page_visitsQuery Params: start_date: date, end_date: dateResponse Model: KPIResponse(value: int)SQL Ref: "KPI: Total Page Visits"Endpoint: GET /api/v1/overview/kpis/page_ctrQuery Params: start_date: date, end_date: dateResponse Model: KPIResponse(value: float) (representing percentage)SQL Ref: "Single Query for Page CTR"Endpoint: GET /api/v1/overview/kpis/total_link_valueQuery Params: start_date: date, end_date: dateResponse Model: KPIResponse(value: float)SQL Ref: "KPI: Total Estimated Link Value"Charts:Endpoint: GET /api/v1/overview/charts/click_trendsQuery Params: start_date: date, end_date: date, breakdown_by_link_type: Optional[bool] = FalseResponse Model: If breakdown_by_link_type is false: TrendResponse. If true, a model like Dict[str, List[TrendDataItem]] or a list of items each having a date, link_type, and value.SQL Ref: "Chart: Overall Click Trends" (adapt for optional breakdown)Endpoint: GET /api/v1/overview/charts/link_type_performanceQuery Params: start_date: Optional[date], end_date: Optional[date]Response Model: BreakdownResponseSQL Ref: "Chart: Link Type Performance"Endpoint: GET /api/v1/overview/charts/geo_hotspotsQuery Params: start_date: Optional[date], end_date: Optional[date], geo_level: str = 'country' (e.g., 'country', 'state')Response Model: BreakdownResponse (category would be country name or state name)SQL Ref: "Chart: Geographic Hotspots"2.3. Campaign Performance Dashboard Endpoints (/api/v1/campaigns/...)Reference SQL queries from section "II. QUERIES FOR 'CAMPAIGN PERFORMANCE DASHBOARD'" in metabase_dashboard_queries. These will require a campaign_natural_key: str path parameter or query parameter.KPIs (for a specific campaign):Endpoint: GET /api/v1/campaigns/{campaign_natural_key}/kpis/total_clicksQuery Params: start_date: Optional[date], end_date: Optional[date]Response Model: KPIResponse(value: int)SQL Ref: "KPI: Total Clicks for a Specific Campaign"(Similarly for ATC Clicks, Page Visits, Page CTR, Link Value for the campaign)Charts & Tables (for a specific campaign):Endpoint: GET /api/v1/campaigns/{campaign_natural_key}/charts/click_trendsQuery Params: start_date: Optional[date], end_date: Optional[date]Response Model: TrendResponseSQL Ref: "Chart: Campaign Click Trend"Endpoint: GET /api/v1/campaigns/{campaign_natural_key}/tables/link_performanceQuery Params: start_date: Optional[date], end_date: Optional[date], page: Optional[int] = 1, size: Optional[int] = 20Response Model: PaginatedTableResponse (with items being LinkPerformanceInCampaignRow Pydantic model)SQL Ref: "Table: Link Performance within a Campaign"Endpoint: GET /api/v1/campaigns/{campaign_natural_key}/charts/utm_performanceQuery Params: start_date: Optional[date], end_date: Optional[date], utm_parameter: str (e.g., 'source', 'medium', 'content', 'term')Response Model: BreakdownResponseSQL Ref: "Chart/Table: UTM Source Performance for a Campaign" (adapt to take utm_parameter as input)2.4. Other Dashboards (Page Analytics, Link Performance, Audience, Product/Retailer)Follow a similar pattern for the other dashboards:Define specific endpoints (e.g., /api/v1/pages/{page_natural_key}/ctr, /api/v1/links/top_performing, /api/v1/audience/geo_distribution).Identify necessary query parameters for filtering (dates, project IDs, link types, etc.).Define appropriate Pydantic response models.Adapt the SQL queries from metabase_dashboard_queries to be parameterized.3. Example FastAPI Path Operation (Conceptual)# main.py (or a router file)
from fastapi import APIRouter, Depends, HTTPException, Query
from typing import List, Optional
from datetime import date
import asyncpg # Assuming asyncpg for database connection

# Import your Pydantic schemas (e.g., from schemas.py)
from . import schemas
# Import your database connection dependency
# from .database import get_connection # Example from above

router = APIRouter(
    prefix="/api/v1/overview",
    tags=["Overview Analytics"],
)

# Placeholder for actual DB connection logic
async def get_db_connection_placeholder():
    # In a real app, this would yield an asyncpg.Connection from a pool
    # For this example, we'll mock it slightly for structure.
    # Replace with your actual get_connection dependency.
    class MockConnection:
        async def fetchval(self, query, *args):
            # Mocked: In reality, execute query and return a single value
            if "total_clicks" in query: return 12345 
            if "total_atc_clicks" in query: return 678
            return 0 
        async def fetch(self, query, *args):
            # Mocked: In reality, execute query and return list of records
            if "click_trends" in query:
                return [{"click_date": date(2023,1,1), "number_of_clicks": 100}, {"click_date": date(2023,1,2), "number_of_clicks": 120}]
            return []

    yield MockConnection()
    # Remember to close/release connection if acquired from a pool in real code

@router.get("/kpis/total_clicks", response_model=schemas.KPIResponse)
async def get_total_clicks(
    start_date: date,
    end_date: date,
    db: asyncpg.Connection = Depends(get_db_connection_placeholder) # Replace with actual get_connection
):
    """
    Get total clicks within a specified date range.
    Corresponds to "KPI: Total Clicks" from metabase_dashboard_queries.
    """
    # SQL query from metabase_dashboard_queries (adapted for parameters)
    query = """
        SELECT COUNT(ffc.clickfactkey) AS total_clicks
        FROM factlinkclicks ffc
        JOIN dimdate dd ON ffc.datekey = dd.datekey
        WHERE dd.fulldate >= $1 AND dd.fulldate <= $2;
    """
    try:
        # In a real scenario with asyncpg:
        # result = await db.fetchval(query, start_date, end_date)
        # For this placeholder:
        result = await db.fetchval(query, start_date, end_date) # This will use the mock
        
        if result is None:
            result = 0 # Default to 0 if no clicks
        return schemas.KPIResponse(value=result)
    except Exception as e:
        # Add proper logging
        raise HTTPException(status_code=500, detail=f"Database query error: {str(e)}")

@router.get("/charts/click_trends", response_model=schemas.TrendResponse)
async def get_click_trends(
    start_date: date,
    end_date: date,
    # breakdown_by_link_type: Optional[bool] = False, # For more complex response
    db: asyncpg.Connection = Depends(get_db_connection_placeholder) # Replace with actual get_connection
):
    """
    Get click trends over a date range.
    Corresponds to "Chart: Overall Click Trends" from metabase_dashboard_queries.
    """
    query = """
        SELECT
            dd.fulldate AS "date", -- Ensure alias matches Pydantic model field
            COUNT(ffc.clickfactkey) AS value
        FROM
            factlinkclicks ffc
        JOIN
            dimdate dd ON ffc.datekey = dd.datekey
        WHERE
            dd.fulldate >= $1 AND dd.fulldate <= $2
        GROUP BY
            dd.fulldate
        ORDER BY
            dd.fulldate ASC;
    """
    try:
        # In a real scenario with asyncpg:
        # records = await db.fetch(query, start_date, end_date)
        # For this placeholder:
        records = await db.fetch(query, start_date, end_date) # This will use the mock

        # Convert records to TrendDataItem if necessary (asyncpg returns list of Record objects)
        # data_items = [schemas.TrendDataItem(date=rec['date'], value=rec['value']) for rec in records]
        # For this placeholder, assuming the mock returns data in the correct shape:
        data_items = [schemas.TrendDataItem(**rec) for rec in records]
        return schemas.TrendResponse(data=data_items)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Database query error: {str(e)}")

# Add your main FastAPI app instance and include the router
# from fastapi import FastAPI
# app = FastAPI()
# app.include_router(router)
4. General API Design ConsiderationsAuthentication & Authorization: Secure your API endpoints. FastAPI offers robust mechanisms for this (e.g., OAuth2 with JWT tokens). Determine who should have access to which data.Error Handling: Implement comprehensive error handling and return meaningful error responses.Pagination: For endpoints returning lists of items (like tables), implement pagination using query parameters (e.g., page: int = 1, size: int = 20).Asynchronous Operations: Use async and await for all database operations to ensure the API remains non-blocking and performant.Parameter Validation: FastAPI and Pydantic handle much of this automatically for query and path parameters.CORS: Configure Cross-Origin Resource Sharing (CORS) if your API will be accessed from different domains than where it's hosted.Logging: Implement structured logging for requests, errors, and important events.5. Swagger/OpenAPI DocumentationFastAPI will automatically generate interactive API documentation (Swagger UI at /docs and ReDoc at /redoc) based on your path operations, Pydantic models, and docstrings. Encourage the developer to write clear docstrings for each endpoint to enhance this documentation.This guide provides a solid starting point. The developer will need to:Set up the FastAPI project.Implement the database connection logic.Define all necessary Pydantic schemas.Translate each required SQL query from metabase_dashboard_queries into a parameterized query within a FastAPI path operation.Thoroughly test each endpoint.Let me know if you have more specific areas you'd like to detail for the developer!